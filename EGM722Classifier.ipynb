{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arcgis.learn import *\n",
    "from arcgis.raster import ImageryLayer\n",
    "from arcgis.gis import GIS\n",
    "from arcpy import *\n",
    "from arcpy.sa import *\n",
    "#from arcpy.ia import *\n",
    "\n",
    "#import arcpy\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "# We will use all hardware cores to try to use parallellism to speed up the training model\n",
    "import multiprocessing\n",
    "\n",
    "# Target file path\n",
    "SourceTile = r\"U:\\ProjectData\\027-15_2018a_4BAND.TIF\"\n",
    "\n",
    "# ImageAnalyst extension is required\n",
    "arcpy.CheckOutExtension(\"ImageAnalyst\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of this project was to identify areas of mixed land cover on orthophotography 4-band raster data (RGB + near infrared) using new-generation deep learning implementations.\n",
    "Deep learning is a type of machine learning with several layers of nonlinear processing which allow users to identify patterns, objects, and pixels through models. It is a significant improvement on previous Machine Learning systems since it does not require vast amounts of training samples produced by expert users. Several ArcGis Pro Deep Learning models support sparse training data with remarkable success. In this project, training data for our models was gathered in intervals of less than 30.\n",
    "\n",
    "There are several different algorithms and deep learning models that can be employed for image classification.  This project is a tool to carry out image classification of land cover by: preprocessing target data, exporting training samples, training and evaluating deep learning models, and displaying results so a human operator can then choose the best fitting model.\n",
    "\n",
    "The first stage of the project consists on preprocessing our raster data.  This is to ensure images will be processed successfully with DL models at a later stage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0 - Enabling GPU and Parallelism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instruct ArcGis Pro to use GPU acceleration for faster processing\n",
    "arcpy.env.processorType = \"GPU\"\n",
    "\n",
    "# multiprocessing.cpu_count() provides the number of cores - in our case, 16.  Splitting \n",
    "arcpy.env.parallelProcessingFactor = (multiprocessing.cpu_count()/100)*3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Preprocessing\n",
    "\n",
    "The first step in our analysis is to convert our target file into a raster object.  Next, we will preprocess our image to enhance.  This will gurantee that the classification process produces the best possible results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Source_Raster = Raster(SourceTile)\n",
    "Source_Raster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sharpening\n",
    "\n",
    "The first preprocessing step is to smooth the target image using the convolution function, which enhances an image with a sharpening 5 X 5 filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14 identifies the 5x5 filter required \n",
    "\n",
    "Smooth_Raster = arcpy.sa.Convolution(Source_Raster, 14)\n",
    "Source_Raster.save()\n",
    "Source_Raster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stretching\n",
    "The next preprocessing stage consists on enhancing an image by changing properties such as brightness, contrast, and gamma. In this case, we use a Sigmoid stretch as it highlights moderate pixel values while maintaining sufficient contrast in the perimeter. The function used applies a sigmoidal function (an S-shaped curve)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"3\" indicates the sigmoid strength level. The minimum value is 0, and the maximum value is 6.\n",
    "\n",
    "Stretched_Raster = arcpy.sa.Stretch(Source_Raster, \"Sigmoid\", 0, None, None, None, True, None, None, None, None, 3)\n",
    "Stretched_Raster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resampling\n",
    "\n",
    "Resampling changes the spatial resolution of a raster dataset and sets rules for aggregating or interpolating values across the new pixel size.  In this case, we will resample the image according to our datase spatial resolution (40 cm) and we will use the \"Nearest\" resampling technique, which is suitable for land cover and discrete data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The new resampled file will be saved in ProjectData.\n",
    "\n",
    "Str_Output_Raster = r\"U:\\ProjectData\\resampled_output.tif\"\n",
    "arcpy.management.Resample(Stretched_Raster, Str_Output_Raster, 0.4, \"Nearest\")\n",
    "Resampled_Raster = Raster(Str_Output_Raster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentation\n",
    "\n",
    "Segmentation allows us to identify objects, features, or segments by grouping adjacent pixels with similar spectral and spatial characteristics. The parameters used are spectral detail = 18, spatial detail = 3, minimum segment size = 25."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Resampled_Raster = SegmentMeanShift(Resampled_Raster, 18, 3, 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check number of bands and check they are 8 bit unsigned.\n",
    "\n",
    "This checks the the number of bands in the code and, if it detects that there are more than 3 bands it will extract the first 3.  This is done as some deep learning algorithms are only able to operate on 3-band raster files.  It assumes a certain RGB order, and that the band to be omitted is the 4th band.  This matches related data and project required but might differt in other environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the band count and value type of the preprocessed raster. Create string to output the raster after saving.\n",
    "\n",
    "Str_Raster_Features_BAND  = arcpy.management.GetRasterProperties(Resampled_Raster, \"BANDCOUNT\")\n",
    "Str_Raster_Features_VALUETYPE  = arcpy.management.GetRasterProperties(Resampled_Raster, \"VALUETYPE\")\n",
    "Str_Output_Raster = r\"U:\\ProjectData\\ThreeBand8Bit_Raster.tif\"\n",
    "\n",
    "#If bandcount <> 4, bands 1, 2 and 3 are extracted\n",
    "if (Str_Raster_Features_BAND.getOutput(0) != 3):\n",
    "    Resampled_Raster = arcpy.ia.ExtractBand(Resampled_Raster, [1, 2, 3])\n",
    "\n",
    "#Copy into a 8 bit unsigned, 3 band file\n",
    "arcpy.management.CopyRaster(Resampled_Raster, Str_Output_Raster, \"\", \"\", \"\", \"NONE\", \"NONE\", \"8_BIT_UNSIGNED\", \"NONE\", \"NONE\", \"TIFF\", \"NONE\", \"\",\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Export Training Data \n",
    "\n",
    "The second stept in our pixel classification journey is to export training data gathered using ArcGis Pro according to the Deep Learning model requierd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definition of values for Export Trainig Data for Deep Learning\n",
    "\n",
    "# inRaster: the target raster file we want to analyse\n",
    "inRaster = r\"U:\\ProjectData\\ThreeBand8Bit_Raster.tif\"\n",
    "\n",
    "# out_folder is the folder which will contain samples and labels produced by the exporting process.\n",
    "out_folder = r\"U:\\ProjectData\\ChipsAndLabels\"\n",
    "\n",
    "# in_training is the feautre class saved from ArcGis Pro\n",
    "in_training = r\"U:\\ProjectData\\trainingsamples.shp\"\n",
    "\n",
    "#Other parametesr for the export training function.\n",
    "\n",
    "image_chip_format = \"TIFF\"\n",
    "tile_size_x = \"256\"\n",
    "tile_size_y = \"256\"\n",
    "stride_x= \"128\"\n",
    "stride_y= \"128\"\n",
    "output_nofeature_tiles= \"ONLY_TILES_WITH_FEATURES\"\n",
    "metadata_format= \"Classified_Tiles\"\n",
    "start_index = 0\n",
    "classvalue_field = \"Classvalue\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This process uses training samples obtained through ArcGis Pro's **Label Objects For Deep Learning** to create two folders: a folder with our sample images (chips) and a folder with labels which will be fed to our Deep Learning Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ExportTrainingDataForDeepLearning(inRaster, out_folder, in_training, image_chip_format,tile_size_x, tile_size_y,stride_x,\n",
    "                                  stride_y,output_nofeature_tiles,metadata_format, start_index,classvalue_field)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we prepare the Chips and Labels to be used in a Deep Learning model.  In this funtion, batch_size determines the number of training samples to be processed for training at one time. The default value is 2.  The higher the value, the quicker the processing. Values which exceed the computer capabilities will return out of memory errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = prepare_data(out_folder, batch_size = 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A UNET model is trained used the chips and labels in the data object. Ignore_classes is a critical parameter.  It contains the list of class values on which the model will not incur loss. It requirses a value of 0 for the model to run because the NoData class is mapped to '0'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = UnetClassifier(data, backbone='resnet34', class_balancing = 'False', mixup= 'False', focal_loss = 'False', ignore_classes=[0], chip_size=224, monitor = 'valid_loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best learning rate for the model is now calculated. The learning rate is the amount of change to the model during each step of the optimization process. It is the most important hyperparameter to tune for a neural network in order to achieve good performance, since it The learning rate hyperparameter controls the rate or speed at which the model learns. The lr_find() function provides the best learning rate for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rate = unet.lr_find()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fit() function trains the model for the specified number of epochs using the specified learning rates.  This feature is very demanding in terms of resources, and it can take many hours to process. To that effect, we used parallelProcessingFactor() to spread the processing of this function between our system hardware cores (16). Spreading a geoprocessing operation across multiple processes can speed up performance and we found out that the processing time was reduced from 308 minutes to 18."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet.fit(20, best_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrics Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet.per_class_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet.save('ModelXVI', framework='PyTorch', publish=True, gis=None, compute_metrics=True, save_optimizer=True, save_inference_file=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#THE KEY WAS TO USE THE DLPK FILE INSIDE THE DLPK FILE CREATED BY THE UNET.\n",
    "\n",
    "model_folder=r\"C:\\Users\\jserr\\ModelXVI.dlpk\"\n",
    "inRaster = r\"C:\\Users\\jserr\\ThreeBand8Bit_Raster.tif\"\n",
    "ClassifiedRaster = r\"C:\\Users\\jserr\\ClassifiedRaster.tif\"\n",
    "out_classified_raster = ClassifyPixelsUsingDeepLearning(inRaster, model_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArcGISPro",
   "language": "Python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
