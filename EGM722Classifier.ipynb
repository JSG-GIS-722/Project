{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enables all Deep Learning Tools.\n",
    "from arcgis.learn import *\n",
    "\n",
    "# Classes and analysis functions for working with raster data and imagery layers\n",
    "from arcgis.raster import ImageryLayer\n",
    "\n",
    "# Access to the GIS services using Python\n",
    "from arcgis.gis import GIS\n",
    "\n",
    "# ArcGis environment for developing Python scripts \n",
    "from arcpy import *\n",
    "from arcpy.sa import *\n",
    "from arcpy.ia import *\n",
    "\n",
    "# Requests allows us to send HTTP/1.1 requests extremely easily.\n",
    "import requests\n",
    "\n",
    "# This module allows us to manage warning.  We chose to disable them to enhance readability.\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# The multiprocessing package side steps the Global Interpreter Lock by using subprocesses instead of threads.\n",
    "# Due to this, the multiprocessing module allows us to fully leverage multiple processors on a given machine.\n",
    "import multiprocessing\n",
    "\n",
    "# Target file path\n",
    "SourceTile = r\"U:\\ProjectData\\027-15_2018a_4BAND.TIF\"\n",
    "\n",
    "# Retrieves the license from the License Manager\n",
    "arcpy.CheckOutExtension(\"ImageAnalyst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" This function trains a Deep Learning Model, saves it and returns a classified raster.\n",
    "\n",
    "Parameters:\n",
    "    mynet:a Classifier object\n",
    "    myiterations: an integer which represents the number of epochs the classifier will be trained for\n",
    "    mytpye: a string which is used to save and retrieve the function output to/from the correct path\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def AClassifier(mynet, myiterations, mytype):\n",
    "      \n",
    "    # The best learning rate for the model is calculated.\n",
    "    best_rate = mynet.lr_find()\n",
    "    \n",
    "    # Trains the model for the specified number of epochs.\n",
    "    mynet.fit(myiterations, best_rate)\n",
    "    \n",
    "    # Builds strings to save the trained model, locate the necessary dlpk file, and create the classified raster\n",
    "    modelpath = r\"U:\\\\ProjectData\\\\Models\\\\\" + mytype\n",
    "    model_folder= modelpath + \"\\\\\" + mytype + \".emd\"\n",
    "    \n",
    "    # Saves model\n",
    "    mynet.save(modelpath, framework='PyTorch', publish=True, gis=None, compute_metrics=True, save_optimizer=True, save_inference_file=True)\n",
    "    \n",
    "    # Returns the classified raster\n",
    "    return ClassifyPixelsUsingDeepLearning(\"U:\\\\ProjectData\\\\ThreeBand8Bit_Raster.tif\", model_folder, \"padding 56; batch_size 8\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of this project was to identify areas of mixed land cover on orthophotography 4-band raster data (RGB + near infrared) using new-generation deep learning implementations.\n",
    "Deep learning is a type of machine learning with several layers of nonlinear processing which allow users to identify patterns, objects, and pixels through models. It is a significant improvement on previous Machine Learning systems since it does not require vast amounts of training samples produced by expert users. Several ArcGis Pro Deep Learning models support sparse training data with remarkable success. In this project, training data for our models was gathered in intervals of less than 30 minutes.\n",
    "\n",
    "There are several different algorithms and deep learning models that can be employed for image classification.  This project is a tool to carry out pixel classification of land cover by preprocessing target data, exporting training samples, training and evaluating deep learning models, and displaying results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0 - Enable GPU and Parallelism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instruct ArcGis Pro to use GPU acceleration for faster processing\n",
    "arcpy.env.processorType = \"GPU\"\n",
    "\n",
    "# Execution of this Notebook is split among 8 (50% x number of cores) processes to speed it up as it can be extremely resource intensive\n",
    "arcpy.env.parallelProcessingFactor = '50%'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Preprocessing\n",
    "\n",
    "Firstly, we transform our target file into a raster object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Source_Raster = Raster(SourceTile)\n",
    "\n",
    "#Extracts 3 bands (1, 2 and 3) as some Deep Learning Processes only suport 3 bands.\n",
    "Source_Raster = arcpy.ia.ExtractBand(Source_Raster, [1, 2, 3])\n",
    "\n",
    "Source_Raster.save(r'U:\\\\ProjectData\\\\SourceRaster.tif')\n",
    "Source_Raster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smoothing\n",
    "\n",
    "Then, we smooth the image using a convolution process, in order to enhance it with a smoothing 5 X 5 filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The parameter '12' identifies the 5x5 filter required \n",
    "Smooth_Raster = arcpy.sa.Convolution(Source_Raster, 12)\n",
    "\n",
    "Smooth_Raster.save(r'U:\\\\ProjectData\\\\Smooth_Raster.tif')\n",
    "Smooth_Raster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stretch\n",
    "The next preprocessing stage consists of enhancing an image by changing properties such as brightness, contrast, and gamma. In this case, we use a PercentClip, as it highlights moderate pixel values while maintaining sufficient contrast in the perimeter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Stretch_raster = arcpy.ia.Stretch(Smooth_Raster, \"PercentClip\", None, None, None, None, True, 0.5, 0.5, None, None, None)\n",
    "\n",
    "Stretch_raster.save(r'U:\\\\ProjectData\\\\Stretch_raster.tif')\n",
    "Stretch_raster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resample\n",
    "\n",
    "Resampling changes the spatial resolution of a raster dataset and sets rules for aggregating or interpolating values across the new pixel size.  In this case, we will resample the image according to our datase spatial resolution (40 cm) and we will use the \"NearestNeighbor\" resampling technique, which is suitable for land cover and discrete data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Resampled_Raster = arcpy.ia.Resample(Stretch_raster, \"NearestNeighbor\")\n",
    "Resampled_Raster.save(r'U:\\\\ProjectData\\\\Resampled.tif')\n",
    "Resampled_Raster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentation\n",
    "\n",
    "Segmentation allows us to identify objects, features, or segments by grouping adjacent pixels with similar spectral and spatial characteristics. The parameters used are spectral detail = 18, spatial detail = 3, minimum segment size = 25.  This will be used outside to produce Chips and Labels and also to select training samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Segmented_Raster = SegmentMeanShift(Resampled_Raster, 18, 3, 25)\n",
    "Segmented_Raster.save(r'U:\\\\ProjectData\\\\Segmented_Raster.tif')\n",
    "Segmented_Raster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save as 8 bit unsigned\n",
    "\n",
    "Finally, the raster is saved in a 8 bit unsigned format to comply with Deep Learning processing requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Str_Output_Raster = r\"U:\\\\ProjectData\\\\ThreeBand8Bit_Raster.tif\"\n",
    "\n",
    "arcpy.management.CopyRaster(Resampled_Raster, Str_Output_Raster, \"\", \"\", \"\", \"NONE\", \"NONE\", \"8_BIT_UNSIGNED\", \"NONE\", \"NONE\", \"TIFF\", \"NONE\", \"\",\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Export Training Data \n",
    "\n",
    "The second stept in our pixel classification journey is to export our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of values for Export Training Data for Deep Learning\n",
    "\n",
    "# The target raster file we want to analyse\n",
    "\n",
    "inRaster = r\"U:\\\\ProjectData\\\\ThreeBand8Bit_Raster.tif\"\n",
    "\n",
    "# The folder which will contain samples and labels produced by the exporting process.\n",
    "\n",
    "out_folder = r\"U:\\\\ProjectData\\\\ChipsAndLabels\"\n",
    "\n",
    "# Feature class saved from ArcGis Pro outside this project, using the Label Objects for Deep Learning menu\n",
    "\n",
    "in_training = r\"U:\\\\ProjectData\\\\trainingsamples.shp\"\n",
    "\n",
    "# Other parameters for ExportTrainingDataForDeepLearning. Classified_Tiles is the key value which tells the function\n",
    "# to prepare data for pixel classification Deep Learning models\n",
    "\n",
    "image_chip_format = \"TIFF\"\n",
    "tile_size_x = \"256\"\n",
    "tile_size_y = \"256\"\n",
    "stride_x= \"128\"\n",
    "stride_y= \"128\"\n",
    "output_nofeature_tiles= \"ONLY_TILES_WITH_FEATURES\"\n",
    "metadata_format= \"Classified_Tiles\"\n",
    "start_index = 0\n",
    "classvalue_field = \"Classvalue\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function uses the feature class of training samples obtained through ArcGis Pro's **Label Objects For Deep Learning** to create two folders which will be used by our Deep Learning model: a folder with image samples (chips) and a folder with labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ExportTrainingDataForDeepLearning(inRaster, out_folder, in_training, image_chip_format,tile_size_x, tile_size_y,stride_x,\n",
    "                                  stride_y,output_nofeature_tiles,metadata_format, start_index,classvalue_field)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Train classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we prepare the Chips and Labels for the Deep Learning model.  In this function, batch_size determines the number of training samples to be processed for training at one time. The default value is 2.  The higher the value, the quicker the processing. Values which exceed the computer capabilities will return **out of memory** errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = prepare_data(out_folder, batch_size = 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "U-NET and PSPNET modesl are trained using the chips and labels in the data object. **Ignore_classes** is a critical parameter here.  It contains the list of class values on which the model will not incur loss. It requires a value of 0 for the model to run successfully because the NoData class is mapped to '0'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a U-Net Classifier object \n",
    "\n",
    "unet = UnetClassifier(data, backbone='resnet34', class_balancing = 'False', mixup= 'False', focal_loss = 'False', ignore_classes=[0], chip_size=224, monitor = 'valid_loss')\n",
    "\n",
    "# Creates a PSPNet Classifier object \n",
    "\n",
    "psp = PSPNetClassifier(data=data, use_unet=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Classify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 2 classifiers are passed on to the custom-built **AClassifier** function. In **AClassifier**, classifiers are trained and the pixel classification is carried out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_classified = AClassifier(unet, 20, 'UNET')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psp_classified = AClassifier(psp, 20, 'PSPNET')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 - Conclussions\n",
    "\n",
    "Finally, both U-Net and PSPNet classified rasters are saved and displayed, which allows to visually verify the results obtained above.  In this exmaple, U-Net provides far better results than PSPNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saves and displays U-Net classified raster\n",
    "unet_classified.save(r\"U:\\\\ProjectData\\ChipsAndLabels\\UnetClassified.tif\")\n",
    "unet_classified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saves and displays PSPNet classified raster\n",
    "psp_classified.save(r\"U:\\\\ProjectData\\ChipsAndLabels\\PSPClassified.tif\")\n",
    "psp_classified"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArcGISPro",
   "language": "Python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
